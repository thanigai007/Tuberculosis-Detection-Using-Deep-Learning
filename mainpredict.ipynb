{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d0fac7-358c-4d36-96ef-b6e8fca87365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Balanced dataset created with 514 Normal and 514 TB images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "normal_path = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Dataset of Tuberculosis Chest X-rays Images/Normal\"\n",
    "tb_path = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Dataset of Tuberculosis Chest X-rays Images/TB\"\n",
    "balanced_tb_path = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Blanced dataset/TB\"\n",
    "balanced_normal_path = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Blanced dataset/Normal\"\n",
    "\n",
    "os.makedirs(balanced_tb_path, exist_ok=True)\n",
    "os.makedirs(balanced_normal_path, exist_ok=True)\n",
    "\n",
    "# Get files\n",
    "normal_files = os.listdir(normal_path)\n",
    "tb_files = os.listdir(tb_path)\n",
    "\n",
    "# Copy normal (all 514)\n",
    "for file in normal_files:\n",
    "    shutil.copy(os.path.join(normal_path, file), balanced_normal_path)\n",
    "\n",
    "# Randomly sample TB to 514\n",
    "tb_sample = random.sample(tb_files, 514)\n",
    "for file in tb_sample:\n",
    "    shutil.copy(os.path.join(tb_path, file), balanced_tb_path)\n",
    "\n",
    "print(\"âœ… Balanced dataset created with 514 Normal and 514 TB images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98c0e16c-b7b6-4a9e-96d4-8d042e1e615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset split into train/val/test at: D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Train Val Test Split\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CHANGE THESE PATHS\n",
    "DATASET_ROOT = r\"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Blanced dataset\"       # raw dataset (Normal/ TB/)\n",
    "OUTPUT_ROOT  = r\"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Train Val Test Split\" # where new folders will be created\n",
    "\n",
    "CLASSES = [\"Normal\", \"TB\"]\n",
    "SPLITS = (0.7, 0.15, 0.15)  # train, val, test\n",
    "\n",
    "def make_dirs():\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        for cls in CLASSES:\n",
    "            os.makedirs(os.path.join(OUTPUT_ROOT, split, cls), exist_ok=True)\n",
    "\n",
    "def split_and_copy():\n",
    "    for cls in CLASSES:\n",
    "        files = [os.path.join(DATASET_ROOT, cls, f) for f in os.listdir(os.path.join(DATASET_ROOT, cls))]\n",
    "        train_files, temp = train_test_split(files, test_size=(1-SPLITS[0]), random_state=42)\n",
    "        val_files, test_files = train_test_split(temp, test_size=SPLITS[2]/(SPLITS[1]+SPLITS[2]), random_state=42)\n",
    "\n",
    "        for f in train_files: shutil.copy(f, os.path.join(OUTPUT_ROOT, \"train\", cls))\n",
    "        for f in val_files:   shutil.copy(f, os.path.join(OUTPUT_ROOT, \"val\", cls))\n",
    "        for f in test_files:  shutil.copy(f, os.path.join(OUTPUT_ROOT, \"test\", cls))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    make_dirs()\n",
    "    split_and_copy()\n",
    "    print(\"âœ… Dataset split into train/val/test at:\", OUTPUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942cecec-6294-4089-af6e-939cf958fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0dc3072-7dea-436d-a793-03edb9eaa7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 718 files belonging to 2 classes.\n",
      "Found 154 files belonging to 2 classes.\n",
      "Found 156 files belonging to 2 classes.\n",
      "âœ… Data ready: train, val, test sets created!\n"
     ]
    }
   ],
   "source": [
    "# Change this to your split dataset path\n",
    "DATA_DIR = r\"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Train Val Test Split\"\n",
    "IMG_SIZE = (224, 224)   # Resize all images to 224x224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 1ï¸âƒ£ Load datasets from folder structure\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR + \"/train\",\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\"  # one-hot for multi-class\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR + \"/val\",\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR + \"/test\",\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# 2ï¸âƒ£ Normalize pixel values (scale 0â€“255 â†’ 0â€“1)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds   = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds  = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# 3ï¸âƒ£ Data Augmentation (apply only on training set)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "# 4ï¸âƒ£ Improve performance with caching & prefetching\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds   = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds  = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"âœ… Data ready: train, val, test sets created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81ffea9-dca7-4b14-a013-f0479a6f9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c26b46-f55c-413f-82bf-3e868e4a9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (Change these accordingly)\n",
    "train_dir = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/train\"\n",
    "val_dir   = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/val\"\n",
    "test_dir  = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdaf9d87-b9f6-4ada-8cac-25bcac650891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 718 images belonging to 2 classes.\n",
      "Found 154 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths\n",
    "train_dir = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Train Val Test Split/train\"\n",
    "val_dir = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Train Val Test Split/val\"\n",
    "\n",
    "# Preprocessing with conversion: grayscale -> RGB\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Training data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),   # Resize to match transfer learning model\n",
    "    color_mode=\"rgb\",         # Convert grayscale -> RGB\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"       # Change to 'categorical' if >2 classes\n",
    ")\n",
    "\n",
    "# Validation data\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",         # Convert grayscale -> RGB\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09011019-407c-4541-8599-db8c06cbb3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74e6abee-339d-456f-9303-0af47148e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (Change these accordingly)\n",
    "train_dir = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Train Val Test Split/train\"\n",
    "val_dir   = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Train Val Test Split/val\"\n",
    "test_dir  = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Train Val Test Split/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adc9b5b4-bb09-4130-abaf-63a53a97018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 718 images belonging to 2 classes.\n",
      "Found 156 images belonging to 2 classes.\n",
      "\n",
      "ğŸ”¹ Training ResNet50...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.4969 - loss: 0.7475 - val_accuracy: 0.5000 - val_loss: 0.6964\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.5572 - loss: 0.7025 - val_accuracy: 0.5449 - val_loss: 0.6871\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.5354 - loss: 0.6958 - val_accuracy: 0.4936 - val_loss: 0.6850\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.5086 - loss: 0.7155 - val_accuracy: 0.5000 - val_loss: 0.6836\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.4704 - loss: 0.7099 - val_accuracy: 0.6346 - val_loss: 0.6799\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ResNet50 Evaluation:\n",
      "Accuracy: 0.6346\n",
      "Precision: 0.5814\n",
      "Recall: 0.9615\n",
      "F1-Score: 0.7246\n",
      "ROC-AUC: 0.9111\n",
      "\n",
      "ğŸ”¹ Training VGG16...\n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4s/step - accuracy: 0.5138 - loss: 0.7158 - val_accuracy: 0.7885 - val_loss: 0.6385\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 4s/step - accuracy: 0.6758 - loss: 0.6453 - val_accuracy: 0.9038 - val_loss: 0.5952\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 4s/step - accuracy: 0.7864 - loss: 0.5894 - val_accuracy: 0.8910 - val_loss: 0.5599\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 4s/step - accuracy: 0.8490 - loss: 0.5458 - val_accuracy: 0.8910 - val_loss: 0.5293\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 4s/step - accuracy: 0.8476 - loss: 0.5235 - val_accuracy: 0.9103 - val_loss: 0.5021\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š VGG16 Evaluation:\n",
      "Accuracy: 0.9103\n",
      "Precision: 0.9444\n",
      "Recall: 0.8718\n",
      "F1-Score: 0.9067\n",
      "ROC-AUC: 0.9574\n",
      "\n",
      "ğŸ”¹ Training EfficientNetB0...\n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.4989 - loss: 0.6983 - val_accuracy: 0.5000 - val_loss: 0.6971\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.5077 - loss: 0.6979 - val_accuracy: 0.5000 - val_loss: 0.6953\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.4650 - loss: 0.7069 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.4977 - loss: 0.7044 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.4765 - loss: 0.7025 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000174E3A4FB00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000174E3A4FB00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 968ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000174E3A4FB00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000174E3A4FB00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š EfficientNetB0 Evaluation:\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "ROC-AUC: 0.9202\n",
      "\n",
      "ğŸ† Best Model: VGG16 with Accuracy: 0.9103\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# -----------------------------\n",
    "# Use your existing generators\n",
    "# -----------------------------\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Train Val Test Split/train\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",  # already RGB\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Train Val Test Split/test\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",  # already RGB\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Model builder function\n",
    "# -----------------------------\n",
    "def build_transfer_model(model_name):\n",
    "    if model_name == \"ResNet50\":\n",
    "        base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "    elif model_name == \"VGG16\":\n",
    "        base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "    elif model_name == \"EfficientNetB0\":\n",
    "        base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model name\")\n",
    "\n",
    "    base_model.trainable = False\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Train and evaluate models\n",
    "# -----------------------------\n",
    "models_list = [\"ResNet50\", \"VGG16\", \"EfficientNetB0\"]\n",
    "results = {}\n",
    "\n",
    "for name in models_list:\n",
    "    print(f\"\\nğŸ”¹ Training {name}...\\n\")\n",
    "    model = build_transfer_model(name)\n",
    "    \n",
    "    # Train\n",
    "    model.fit(train_generator, validation_data=val_generator, epochs=5)  # adjust epochs if needed\n",
    "    \n",
    "    # Predictions\n",
    "    y_true = val_generator.classes\n",
    "    y_pred_prob = model.predict(val_generator).ravel()\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc = roc_auc_score(y_true, y_pred_prob)\n",
    "    \n",
    "    results[name] = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1_score\": f1, \"roc_auc\": roc}\n",
    "    \n",
    "    print(f\"\\nğŸ“Š {name} Evaluation:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    os.makedirs(\"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/save models\", exist_ok=True)\n",
    "    model.save(f\"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/save models/{name}_tb_model.h5\")\n",
    "\n",
    "# -----------------------------\n",
    "# Select best model\n",
    "# -----------------------------\n",
    "best_model_name = max(results, key=lambda x: results[x][\"accuracy\"])\n",
    "print(f\"\\nğŸ† Best Model: {best_model_name} with Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f72532-261a-47c1-b583-d9dd8f34cc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
