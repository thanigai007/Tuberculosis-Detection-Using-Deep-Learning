{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c0e16c-b7b6-4a9e-96d4-8d042e1e615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset split into train/val/test at: D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CHANGE THESE PATHS\n",
    "DATASET_ROOT = r\"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/Dataset of Tuberculosis Chest X-rays Images\"       # raw dataset (Normal/ TB/)\n",
    "OUTPUT_ROOT  = r\"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split\" # where new folders will be created\n",
    "\n",
    "CLASSES = [\"Normal\", \"TB\"]\n",
    "SPLITS = (0.7, 0.15, 0.15)  # train, val, test\n",
    "\n",
    "def make_dirs():\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        for cls in CLASSES:\n",
    "            os.makedirs(os.path.join(OUTPUT_ROOT, split, cls), exist_ok=True)\n",
    "\n",
    "def split_and_copy():\n",
    "    for cls in CLASSES:\n",
    "        files = [os.path.join(DATASET_ROOT, cls, f) for f in os.listdir(os.path.join(DATASET_ROOT, cls))]\n",
    "        train_files, temp = train_test_split(files, test_size=(1-SPLITS[0]), random_state=42)\n",
    "        val_files, test_files = train_test_split(temp, test_size=SPLITS[2]/(SPLITS[1]+SPLITS[2]), random_state=42)\n",
    "\n",
    "        for f in train_files: shutil.copy(f, os.path.join(OUTPUT_ROOT, \"train\", cls))\n",
    "        for f in val_files:   shutil.copy(f, os.path.join(OUTPUT_ROOT, \"val\", cls))\n",
    "        for f in test_files:  shutil.copy(f, os.path.join(OUTPUT_ROOT, \"test\", cls))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    make_dirs()\n",
    "    split_and_copy()\n",
    "    print(\"✅ Dataset split into train/val/test at:\", OUTPUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942cecec-6294-4089-af6e-939cf958fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0dc3072-7dea-436d-a793-03edb9eaa7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2913 files belonging to 2 classes.\n",
      "Found 881 files belonging to 2 classes.\n",
      "Found 877 files belonging to 2 classes.\n",
      "✅ Data ready: train, val, test sets created!\n"
     ]
    }
   ],
   "source": [
    "# Change this to your split dataset path\n",
    "DATA_DIR = r\"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split\"\n",
    "IMG_SIZE = (224, 224)   # Resize all images to 224x224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 1️⃣ Load datasets from folder structure\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR + \"/train\",\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\"  # one-hot for multi-class\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR + \"/val\",\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR + \"/test\",\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# 2️⃣ Normalize pixel values (scale 0–255 → 0–1)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds   = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds  = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# 3️⃣ Data Augmentation (apply only on training set)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "# 4️⃣ Improve performance with caching & prefetching\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds   = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds  = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"✅ Data ready: train, val, test sets created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81ffea9-dca7-4b14-a013-f0479a6f9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c26b46-f55c-413f-82bf-3e868e4a9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (Change these accordingly)\n",
    "train_dir = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/train\"\n",
    "val_dir   = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/val\"\n",
    "test_dir  = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdaf9d87-b9f6-4ada-8cac-25bcac650891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2913 images belonging to 2 classes.\n",
      "Found 877 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths\n",
    "train_dir = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/train\"\n",
    "val_dir = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/test\"\n",
    "\n",
    "# Preprocessing with conversion: grayscale -> RGB\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Training data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),   # Resize to match transfer learning model\n",
    "    color_mode=\"rgb\",         # Convert grayscale -> RGB\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"       # Change to 'categorical' if >2 classes\n",
    ")\n",
    "\n",
    "# Validation data\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",         # Convert grayscale -> RGB\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09011019-407c-4541-8599-db8c06cbb3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e6abee-339d-456f-9303-0af47148e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (Change these accordingly)\n",
    "train_dir = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/train\"\n",
    "val_dir   = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/val\"\n",
    "test_dir  = \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc9b5b4-bb09-4130-abaf-63a53a97018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2913 images belonging to 2 classes.\n",
      "Found 881 images belonging to 2 classes.\n",
      "\n",
      "🔹 Training ResNet50...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.7707 - loss: 0.5407 - val_accuracy: 0.8252 - val_loss: 0.4613\n",
      "Epoch 2/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 2s/step - accuracy: 0.8215 - loss: 0.4844 - val_accuracy: 0.8252 - val_loss: 0.4565\n",
      "Epoch 3/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.8156 - loss: 0.4761 - val_accuracy: 0.8252 - val_loss: 0.4522\n",
      "Epoch 4/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.8233 - loss: 0.4579 - val_accuracy: 0.8252 - val_loss: 0.4485\n",
      "Epoch 5/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.8139 - loss: 0.4685 - val_accuracy: 0.8252 - val_loss: 0.4725\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 ResNet50 Evaluation:\n",
      "Accuracy: 0.8252\n",
      "Precision: 0.8252\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.9042\n",
      "ROC-AUC: 0.9501\n",
      "\n",
      "🔹 Training VGG16...\n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 4s/step - accuracy: 0.7860 - loss: 0.4985 - val_accuracy: 0.8252 - val_loss: 0.3888\n",
      "Epoch 2/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 4s/step - accuracy: 0.8325 - loss: 0.3772 - val_accuracy: 0.8263 - val_loss: 0.3352\n",
      "Epoch 3/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 4s/step - accuracy: 0.8289 - loss: 0.3401 - val_accuracy: 0.8456 - val_loss: 0.2928\n",
      "Epoch 4/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 4s/step - accuracy: 0.8519 - loss: 0.2980 - val_accuracy: 0.8774 - val_loss: 0.2603\n",
      "Epoch 5/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 4s/step - accuracy: 0.8782 - loss: 0.2658 - val_accuracy: 0.8888 - val_loss: 0.2369\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 VGG16 Evaluation:\n",
      "Accuracy: 0.8888\n",
      "Precision: 0.8831\n",
      "Recall: 0.9972\n",
      "F1-Score: 0.9367\n",
      "ROC-AUC: 0.9833\n",
      "\n",
      "🔹 Training EfficientNetB0...\n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1s/step - accuracy: 0.8206 - loss: 0.4818 - val_accuracy: 0.8252 - val_loss: 0.4653\n",
      "Epoch 2/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.8196 - loss: 0.4798 - val_accuracy: 0.8252 - val_loss: 0.4655\n",
      "Epoch 3/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 1s/step - accuracy: 0.8191 - loss: 0.4800 - val_accuracy: 0.8252 - val_loss: 0.4652\n",
      "Epoch 4/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.8254 - loss: 0.4663 - val_accuracy: 0.8252 - val_loss: 0.4640\n",
      "Epoch 5/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.8334 - loss: 0.4560 - val_accuracy: 0.8252 - val_loss: 0.4638\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 993ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 EfficientNetB0 Evaluation:\n",
      "Accuracy: 0.8252\n",
      "Precision: 0.8252\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.9042\n",
      "ROC-AUC: 0.8481\n",
      "\n",
      "🏆 Best Model: VGG16 with Accuracy: 0.8888\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# -----------------------------\n",
    "# Use your existing generators\n",
    "# -----------------------------\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/train\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",  # already RGB\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    \"D:/Project/Guvi_Project/Tuberculosis Detection Using Deep Learning/Dataset/train test split/val\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",  # already RGB\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Model builder function\n",
    "# -----------------------------\n",
    "def build_transfer_model(model_name):\n",
    "    if model_name == \"ResNet50\":\n",
    "        base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "    elif model_name == \"VGG16\":\n",
    "        base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "    elif model_name == \"EfficientNetB0\":\n",
    "        base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model name\")\n",
    "\n",
    "    base_model.trainable = False\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Train and evaluate models\n",
    "# -----------------------------\n",
    "models_list = [\"ResNet50\", \"VGG16\", \"EfficientNetB0\"]\n",
    "results = {}\n",
    "\n",
    "for name in models_list:\n",
    "    print(f\"\\n🔹 Training {name}...\\n\")\n",
    "    model = build_transfer_model(name)\n",
    "    \n",
    "    # Train\n",
    "    model.fit(train_generator, validation_data=val_generator, epochs=5)  # adjust epochs if needed\n",
    "    \n",
    "    # Predictions\n",
    "    y_true = val_generator.classes\n",
    "    y_pred_prob = model.predict(val_generator).ravel()\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc = roc_auc_score(y_true, y_pred_prob)\n",
    "    \n",
    "    results[name] = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1_score\": f1, \"roc_auc\": roc}\n",
    "    \n",
    "    print(f\"\\n📊 {name} Evaluation:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    os.makedirs(\"saved_models\", exist_ok=True)\n",
    "    model.save(f\"saved_models/{name}_tb_model.h5\")\n",
    "\n",
    "# -----------------------------\n",
    "# Select best model\n",
    "# -----------------------------\n",
    "best_model_name = max(results, key=lambda x: results[x][\"accuracy\"])\n",
    "print(f\"\\n🏆 Best Model: {best_model_name} with Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f72532-261a-47c1-b583-d9dd8f34cc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
